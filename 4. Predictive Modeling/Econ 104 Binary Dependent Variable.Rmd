---
title: "Econ 104 Project 3"
author: "Group 12"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 3
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      out.width = "75%", fig.align = "center")
```

\pagebreak

```{r}
# Libraries
library(AER)
library(plm)
library(gplots)
library(tidyr)
library(broom)
library(knitr)
library(margins)
library(corrplot)
```


# 2. Binary Dependent Variables
```{r}
# Loading SwissLabor dataset
data(SwissLabor)

# Replacing yes/no to 1 and 0
SwissLabor$participation <- ifelse(SwissLabor$participation == "yes", 1, 0)
SwissLabor$foreign <- ifelse(SwissLabor$foreign == "yes", 1, 0)
```


## (a) Briefly discuss your data and the question you are trying to answer with your model.

#### Citation
```{r}
citation("AER")
```

The dataset chosen for this part of the project is `SwissLabor`, which contains 872 observations on 7 variables. `SwissLabor` is a binary dependent variable dataset that consists of one binary dependent variable and six independent variables, including:




**Dependent Varaible**

  - `participation (binary variable)`: Factor. Did the individual participate in the labor force?

**Independent Varaible**

  - `income`(continous variable): Logarithm of nonlabor income. 
  
  - `age`(discrete variable): Age in decades (years divided by 10). 
  
  - `education` (discrete variable): Years of formal education. 
  
  - `youngkids` (discrete variable): Number of young children (under 7 years of age). 
  
  - `oldkids` (discrete variable): Number of older children (over 7 years of age). 
  
  - `foreign` (indicator variable): Factor. Is the individual a foreigner (i.e., not Swiss)? 
  
As shown above, there are 1 continuous, 4 discrete, and 1 indicator variable and the dependent variable is a binary variable.
 

The objective of this portion of the project is to identify how the different values of independent variables influence the probability of getting a certain outcome. We will be attempting to build a predictive model that predicts the outcome of the binary dependent variable (`participation`; yes or no) by investigating the relationship between the dependent and independent variables and estimating the marginal effect of each variable.

Furthermore, with the model built within the project, we will attempt to predict the outcome, and how likely a person would participate in the workforce in a hypothetical situation. (e.g. an x-year-old person with a log-non-labor income of y and z years of education, etc...)

The detailed descriptions of the variables in the dataset will be further discussed in part(b).





\pagebreak

## (b) Provide a descriptive analysis of your variables. This should include RELEVANT histograms and fitted distributions, correlation plot, boxplots, scatterplots, and statistical summaries (e.g., the five- number summary). All figures must include comments. For binary variables, you can simply include the proportions of each factor.

#### Statistical Summaries:

Before getting into the detailed descriptive analysis of each variable, the five number statistical summaries below provide a general idea of what variables we are dealing with.
```{r}
kable(summary(SwissLabor))
```



### Binary Dependent Variable

#### `participation`:
People who were participated in the labor force is 45.99% (401 observation) and the rest of the people, approximately 54% of the people (471 observation), did not participate in the workforce.
```{r}
# Barplot of participation

barplot(table(SwissLabor$participation) / length(SwissLabor$participation), 
        main = "Barplot of Participation",
        xlab = "Participation", ylab = "Percentage (%)",
        col = "plum3")

```



### Independent Variables

#### `income` :
Logarithm of nonlabor income. The `income` variable is slightly left-skewed, and as seen in the 5-number statistical summaries and the box plot, more than 75% of the observations have log-nonlabor income of 10-11, which is about $22,000 - $60,000.
```{r}
par(mfrow = c(1,2))
hist(SwissLabor$income, prob = TRUE,
     main = "Histrogram of Income",
     xlab = "Income", ylim = c(0,1.5), col = "red")
lines(density(SwissLabor$income), col = "red4")
boxplot(SwissLabor$income, horizontal = TRUE,
        main = "Boxplot of Income", col = "salmon")

```




#### `age` : 
Age in decades (years divided by 10). The `age` variable is slightly right-skewed and is spread out. 
```{r}
par(mfrow = c(1,2))
hist(SwissLabor$age, prob = TRUE,
     main = "Histogram of Age",
     xlab = "Age", col = "blue")
lines(density(SwissLabor$age), col = "blue4")
boxplot(SwissLabor$age, horizontal = TRUE,
        main = "Boxplot of Age", col = "skyblue3")

```




#### `education` : 
Years of formal education. The `education` variable seems to be slightly right-skewed.
```{r}

par(mfrow = c(1,2))
hist(SwissLabor$education, prob = TRUE,
     main = "Histogram of Education",
     xlab = "Years of Education (divided by 10)",
     ylim = c(0, 0.15), col = "green")
lines(density(SwissLabor$education), col = "green4")
boxplot(SwissLabor$education, horizontal = TRUE,
        main = "Boxplot of Education", col = "lightgreen")

```


#### `youngkids` :
Number of young children (under 7 years of age). Approximately, 76.3% of the people have no young kids, 16.9% have 1 young kid, about 6% have 2 young kids, and less than 1% of the people have 3 young kids.
```{r}
# Barplot of youngkids

barplot(table(factor(SwissLabor$youngkids)) / length(SwissLabor$youngkids),
     main = "Barplot of youngkids (%)",
     xlab = "Number of Young Kids (under 7 years of age)",
     ylab = "Percentage(%)",
     col = "orange")


```



#### `oldkids` : 
Number of older children (over 7 years of age). Starting from the left bar, about 45% have no kids, 22.7% have 1 kid, 23.8% have 2 kids, 6% have 3 kids, 1.6% have 4 kids, 0.2% have 5 kids, and 0.2% have 6 kids that are over 7 years old.
```{r}
# Barplot of oldkids variable

barplot(table(factor(SwissLabor$oldkids)) / length(SwissLabor$oldkids),
     main = "Barplot of oldkids (%)",
     xlab = "Number of Old Kids (over 7 years of age)",
     ylab = "Percentage(%)",
     col = "purple3")



```

#### `foreign` : 
Factor. Is the individual a foreigner (i.e., not Swiss)? Approximately 75% are citizens of Switzerland and 25% of the people are foreigners (not Swiss).
```{r}
# Barplot of foreign variable
barplot(table(factor(SwissLabor$foreign)) / length(SwissLabor$foreign),
        main = "Is the individual a foreigner?",
        xlab = "Yes/No",
        ylab = "Percentage (%)",
        col = "brown")


```


#### Correlation Matrix and relationships between variables
```{r}
corrplot(cor(SwissLabor), lower = "pie", upper = "color", addCoef.col="black")
plot(SwissLabor)

```

The correlations between the dependent variable and the independent variables are not that strong, but we can still see that `income`, `age`, `education`, and `youngkids` are negatively correlated to our binary dependent variable, which means an increase in them leads to a decrease in the probability of participating in the workforce. On the contrary, `oldkids` and `foreign` are positively correlated, meaning that an increase in them results in an increase in the dependent variable `participation`. 

Intuitively, these make some sense. For example, parents of young children often need more time to take care of them, resulting in them not working a job. Thus, resulting in the negative correlation for the `youngkids` variable and positive correlation for `oldkids`.


\pagebreak

## (c) Fit the three models below, and identify which model is your preferred one and why. Make sure to include statistical diagnostics to support your conclusion, and to comment on your findings.


### â€¢ Linear Probability Model

```{r}
# Linear Probability Model
lin_mod <- lm(participation ~ income + age + education + youngkids +
                oldkids + foreign, data = SwissLabor)

kable(tidy(lin_mod))


```

For the LPM model, interpreting the marginal effects of the model is relatively straight forward since the marginal effects are constant, which means the coefficient estimates are the marginal effects. But, the effects being constant also implies the following issues:

1. the probability of getting a certain outcome could exceed 1 or could be below 0 (negative)
2. The variance is heteroskedastic, which means robust standard errors or FGLS should be used


#### Correcting the standard errors using robust standard errors
```{r}
kable(tidy(coeftest(lin_mod, vcov = hccm(lin_mod, type = "hc1"))))
```

#### interpreting the Marginal Effects:
\
For example, the average marginal effect (AME) for the `income` variable is **-0.1679172**. This means that every one-unit increase in `income` (Log-nonlabor income)  leads to approximately 16.7% decrease in the probability of one participating in the labor force, and the same logic applies to the other variables as well.


*Note: `education` and `oldkids` variables are not statistically significant, but were still included in the model just for consistency with the other models*





#### Prediction with LPM
\
Our LPM predicted that 538 people would not participate and 334 people would participate in the workforce while the real outcome is 471 and 401 respectively.
```{r}
lin_predict <- ifelse(lin_mod$fitted.values >= 0.5, 1,0)

actual_values <- table(SwissLabor$participation)
predicted_values <- table(lin_predict)

# Combine the tables into one data frame
combined_table <- data.frame(Actual = actual_values, 
                             Predicted = predicted_values)[,c(2,4)]

rownames(combined_table) <- c("No", "Yes")
kable(combined_table)

# Bar plot
barplot(as.matrix(combined_table), beside = FALSE, col = c("blue", "red"),
        legend.text = c("Participated", "Not Participated"), 
        args.legend = list(x = "topright"), 
        xlim = c(0,4))
grid()
# Add axis labels and a title
title(main = "Actual vs. Predicted Participation", xlab = "Participation", ylab = "Count")



```


#### Assessing the performance of LMP
```{r}
# Calculating the probability of LPM correctly predicts the true outcome
sum(SwissLabor$participation == lin_predict) / length(SwissLabor$participation)
AIC(lin_mod)
```

As shown above, the probability of LPM correctly predicting the true outcome is approximately 66.6%, and the AIC of the model is 1126.542. These results will be compared with the other models and will be further discussed.





*Note: 0.5 threshold was used for this prediction.*


\pagebreak
### â€¢ Probit Model


```{r}
probit_mod <- glm(participation ~ income + age + education + youngkids + 
                    oldkids + foreign, data = SwissLabor, 
                    family = binomial(link = "probit"))
kable(tidy(probit_mod))

```

#### interpreting the Marginal Effects
```{r}
kable(tidy(margins(probit_mod)))
```

Based on the result above (probit marginal effects), we can say that one unit increase in `income` (Log-nonlabor income) leads to approximately 17.3% decrease in the probability of one participating in the labor force, and the same logic applies to the other variables as well. Overall, the probit model estimates the marginal effects slightly higher than LPM did.




#### Prediction with the Probit Model:
\
Our probit model predicted that 537 people would not participate and 335 people would participate in the work force while the real outcome is 471 and 401 respectively.
```{r}
probit_predict <- ifelse(probit_mod$fitted.values >= 0.5, 1,0)

actual_values <- table(SwissLabor$participation)
predicted_values <- table(probit_predict)

# Combine the tables into one data frame
combined_table <- data.frame(Actual = actual_values, 
                             Predicted = predicted_values)[,c(2,4)]

rownames(combined_table) <- c("No", "Yes")
kable(combined_table)

# Bar plot
barplot(as.matrix(combined_table), beside = FALSE, col = c("blue", "red"),
        legend.text = c("Participated", "Not Participated"), 
        args.legend = list(x = "topright"),
        xlim = c(0,4))
grid()
# Add axis labels and a title
title(main = "Actual vs. Predicted Participation", 
      xlab = "Participation", ylab = "Count")

```


#### Assessing the performance of Probit Model
```{r}
# Calculating the probability of LPM correctly predicts the true outcome
sum(SwissLabor$participation == 
      probit_predict) / length(SwissLabor$participation)
AIC(probit_mod)
```


As shown above, the probability of the probit model correctly predicting the true outcome is approximately 66.5%, and the AIC of the model is 1066.983. while the percentage that the probit model and the LPM correctly predicted the outcomes were almost the same, the probit model indicates better performance in AIC.

*Note: 0.5 threshold was used for this prediction.*

\pagebreak

### â€¢ Logit Model

```{r}
# Logit Model
logit_mod <- glm(participation ~ income + age + education + youngkids + 
                    oldkids + foreign, data = SwissLabor, 
                    family = binomial(link = "logit"))
kable(tidy(lin_mod))


```

#### interpreting the Marginal Effects of the logit model
```{r}
kable(tidy(margins(logit_mod)))
```

Based on the result above (logit marginal effects), we can say that one unit increase in `income` (Log-nonlabor income) leads to approximately 16.99% decrease in the probability of one participating in the labor force, and the same logic applies to the other variables as well. Overall, the logit model estimates the marginal effects slightly lower, compared to the probit model.



#### Prediction with the Logit Model:
\
Our logit model predicted that 538 people would not participate and 334 people would participate in the work force while the real outcome is 471 and 401 respectively.
```{r}
logit_predict <- ifelse(logit_mod$fitted.values >= 0.5, 1,0)

actual_values <- table(SwissLabor$participation)
predicted_values <- table(logit_predict)

# Combine the tables into one data frame
combined_table <- data.frame(Actual = actual_values, 
                             Predicted = predicted_values)[,c(2,4)]

rownames(combined_table) <- c("No", "Yes")
kable(combined_table)

# Bar plot
barplot(as.matrix(combined_table), beside = FALSE, col = c("blue", "red"),
        legend.text = c("Participated", "Not Participated"), 
        args.legend = list(x = "topright"),
        xlim = c(0,4))
grid()
# Add axis labels and a title
title(main = "Actual vs. Predicted Participation", 
      xlab = "Participation", ylab = "Count")

```
#### Assessing the performance of Logit Model
```{r}
# Calculating the probability of LPM correctly predicts the true outcome
sum(SwissLabor$participation == 
      logit_predict) / length(SwissLabor$participation)
AIC(logit_mod)
```


As shown above, the probability of the logit model correctly predicting the true outcome is approximately 66.6%, and the AIC of the model is 1066.793.


## (d) Comparing the three models:
\
Although the AIC values are very close between the probit model and the logit model, the logit model shows a slightly better performance AIC as well as the probability of predicting the outcomes correctly.
```{r}
data.frame(LPM = c(sum(SwissLabor$participation == 
                  lin_predict) / length(SwissLabor$participation), 
                  AIC(lin_mod)),
Probit = c(sum(SwissLabor$participation == 
                  probit_predict) / length(SwissLabor$participation), 
                  AIC(probit_mod)),
Logit = c(sum(SwissLabor$participation == 
                  logit_predict) / length(SwissLabor$participation), 
                  AIC(logit_mod)))
```

***Therefore, the logit model best describes the data based on the predictive performance.***


## (e) Creating a function that could predict any inputs using the logit model:
\
Using the best model we have selected, I have created a function, using the logit model estimates, that takes any values of independent variables. So now, we can predict the probability of one participating in the labor force in a hypothetical situation.


```{r}
coef(logit_mod)
intercept <- coef(logit_mod)[[1]]
b2 <- coef(logit_mod)[[2]]
b3 <- coef(logit_mod)[[3]]
b4 <- coef(logit_mod)[[4]]
b5 <- coef(logit_mod)[[5]]
b6 <- coef(logit_mod)[[6]]
b7 <- coef(logit_mod)[[7]]

my_logit <- function (income, age, education, youngkids, oldkids, foreign) {
  prob_participate <- 1 / (1 + exp(-(intercept + b2*income + b3*age + 
                                      b4*education + b5*youngkids + 
                                      b6*oldkids + b7*foreign)))
  prob_participate
}

```


#### Q. What is the probability that a 40-year-old foreigner with a nonlabor income of $20,000, 10 years of education, 2 young kids, and 1 old kid participates in the labor force in Swiss?


```{r}
# Testing
# a 40 years old foreigner with non labor income of $20,000, 
# 10 years of education, 2 young kids, 1 old kid

income <- log(20000) # $20,000 of nonlabor income
age <- 40 / 10 # 40 years old
education <- 10 # 10 years of education
youngkids <- 2 # 2 young kids
oldkids <- 1 # 1 old kid
foreign <- 1 # TRUE


my_logit(income, age, education, youngkids, oldkids, foreign)
```

The logit model outputs that the person in question would participate in the labor force in Switzerland with the probability of approximately 31%.





